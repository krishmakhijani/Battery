{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "matplotlib.use('Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = None\n",
    "comparison_notdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestEnteries(num_entries=5000):\n",
    "    print(\"\\nRandom Forest Classifier enteries: \")\n",
    "    start_date = datetime.now()\n",
    "    dates = [start_date + timedelta(minutes=15 * i) for i in range(num_entries)]\n",
    "\n",
    "    battery_levels = []\n",
    "    current_level = 80\n",
    "\n",
    "    for i in range(num_entries):\n",
    "        change = np.random.normal(0, 1.5)\n",
    "\n",
    "        if current_level <= 20:\n",
    "            change = abs(change) * 1.5\n",
    "        elif current_level >= 90:\n",
    "            change = -abs(change)\n",
    "\n",
    "        if np.random.random() < 0.02:\n",
    "            change *= np.random.choice([-2, 2])\n",
    "\n",
    "        current_level += change\n",
    "        current_level = np.clip(current_level, 0, 100)\n",
    "        battery_levels.append(current_level)\n",
    "\n",
    "    data = {\n",
    "        'Timestamp': dates,\n",
    "        'Battery Level': battery_levels,\n",
    "        'Network Status': np.random.choice(['wifi', 'cellular'], num_entries, p=[0.7, 0.3]),\n",
    "        'Power State': ['charging' if level <= 20 else 'unplugged' for level in battery_levels],\n",
    "        'Bluetooth Connected': np.random.choice(['Yes', 'No'], num_entries, p=[0.6, 0.4]),\n",
    "        'Location Enabled': np.random.choice(['Yes', 'No'], num_entries, p=[0.8, 0.2]),\n",
    "        'Brightness': [min(100, max(0, np.random.normal(60, 10))) for _ in range(num_entries)],\n",
    "        'Total Usage Time': [f\"{np.random.randint(0, 30)}m {np.random.randint(0, 59)}s\" for _ in range(num_entries)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Generated dataset with {num_entries} entries!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration_to_seconds(duration):\n",
    "    if isinstance(duration, str):\n",
    "        minutes = seconds = 0\n",
    "        parts = duration.split(' ')\n",
    "        for part in parts:\n",
    "            if 'm' in part:\n",
    "                minutes = int(part.replace('m', ''))\n",
    "            elif 's' in part:\n",
    "                seconds = int(part.replace('s', ''))\n",
    "        return minutes * 60 + seconds\n",
    "    return 0\n",
    "\n",
    "def create_day_sequences(data, timestamps):\n",
    "    xs, ys, ts = [], [], []\n",
    "    for i in range(47, len(data), 48):\n",
    "        x = data[i-47:i, :]\n",
    "        y = data[i, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        ts.append(timestamps[i])\n",
    "    return np.array(xs), np.array(ys), ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, attention_size):\n",
    "        super(xLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.attention_size = attention_size\n",
    "        self.attention = nn.Linear(hidden_size, attention_size)\n",
    "        self.context_vector = nn.Linear(attention_size, 1, bias=False)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def attention_layer(self, lstm_output):\n",
    "        attention_scores = torch.tanh(self.attention(lstm_output))\n",
    "        attention_weights = torch.softmax(self.context_vector(attention_scores), dim=1)\n",
    "        weighted_lstm_output = lstm_output * attention_weights\n",
    "        context_vector = torch.sum(weighted_lstm_output, dim=1)\n",
    "        return context_vector\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output, (hn, cn) = self.lstm(x)\n",
    "        attention_output = self.attention_layer(lstm_output)\n",
    "        attention_output = self.dropout(attention_output)\n",
    "        out = self.fc(attention_output)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scaler(scaler_file_path):\n",
    "    try:\n",
    "        with open(scaler_file_path, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        print(f\"Scaler loaded from {scaler_file_path}\")\n",
    "        return scaler\n",
    "    except FileNotFoundError:\n",
    "        print(\"No existing scaler found. Creating a new one.\")\n",
    "        return MinMaxScaler()\n",
    "\n",
    "def save_scaler(scaler, scaler_file_path):\n",
    "    with open(scaler_file_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(f\"Scaler saved to {scaler_file_path}\")\n",
    "\n",
    "def load_model_metadata(metadata_file_path):\n",
    "    try:\n",
    "        with open(metadata_file_path, 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        print(f\"Loaded model metadata from {metadata_file_path}\")\n",
    "        return metadata\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No existing metadata found at {metadata_file_path}.\")\n",
    "        return None\n",
    "\n",
    "def save_model(model, file_path, metadata_file_path):\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    print(f\"Model weights saved to {file_path}\")\n",
    "    metadata = {\n",
    "        \"input_size\": model.lstm.input_size,\n",
    "        \"hidden_size\": model.lstm.hidden_size,\n",
    "        \"attention_size\": model.attention_size,\n",
    "    }\n",
    "    with open(metadata_file_path, 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"Model metadata saved to {metadata_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Main Process Function\n",
    "def process_data(data_path):\n",
    "    try:\n",
    "        # Data generation and preprocessing\n",
    "        data = RandomForestEnteries(5000)\n",
    "        data.set_index('Timestamp', inplace=True)\n",
    "\n",
    "        # Convert usage time and map categorical variables\n",
    "        data['Total Usage Time'] = data['Total Usage Time'].apply(convert_duration_to_seconds)\n",
    "\n",
    "        network_status_mapping = {'wifi': True, 'cellular': False}\n",
    "        power_state_mapping = {'charging': True, 'unplugged': False}\n",
    "        bluetooth_connected_mapping = {'Yes': True, 'No': False}\n",
    "        location_enabled_mapping = {'Yes': True, 'No': False}\n",
    "\n",
    "        data['Network Status'] = data['Network Status'].map(network_status_mapping)\n",
    "        data['Power State'] = data['Power State'].map(power_state_mapping)\n",
    "        data['Bluetooth Connected'] = data['Bluetooth Connected'].map(bluetooth_connected_mapping)\n",
    "        data['Location Enabled'] = data['Location Enabled'].map(location_enabled_mapping)\n",
    "\n",
    "        # Data preparation\n",
    "        cleaned_data = pd.get_dummies(data, columns=['Network Status', 'Power State', 'Bluetooth Connected', 'Location Enabled'], drop_first=True)\n",
    "\n",
    "        scaler = load_scaler('scaler.pkl')\n",
    "        data_scaled = scaler.fit_transform(cleaned_data)\n",
    "        save_scaler(scaler, 'scaler.pkl')\n",
    "\n",
    "        X, y, timestamps = create_day_sequences(data_scaled, data.index)\n",
    "        X_train, X_test, y_train, y_test, ts_train, ts_test = train_test_split(X, y, timestamps, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "        # Model setup\n",
    "        metadata = load_model_metadata('xlstm_metadata.pkl')\n",
    "        if metadata:\n",
    "            input_size = metadata['input_size']\n",
    "            hidden_size = metadata['hidden_size']\n",
    "            attention_size = metadata['attention_size']\n",
    "            print(\"Reusing model architecture from saved metadata.\")\n",
    "        else:\n",
    "            input_size = len(cleaned_data.columns)\n",
    "            hidden_size = 64\n",
    "            attention_size = 32\n",
    "            print(\"No metadata found. Using default architecture.\")\n",
    "\n",
    "        model = xLSTM(input_size, hidden_size, attention_size)\n",
    "\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('xlstm_weights.pth'))\n",
    "            print(\"Loaded existing model weights from xlstm_weights.pth\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No existing model weights found. Training from scratch.\")\n",
    "\n",
    "        # Model training\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        if metadata is None:\n",
    "            print(\"\\nTraining xLSTM model:\")\n",
    "            pbar = tqdm(range(300), desc='Training', ncols=100)\n",
    "            for epoch in pbar:\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_train_tensor)\n",
    "                loss = criterion(outputs, y_train_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_description(f'Epoch {epoch+1}/300 | Loss: {loss.item():.4f}')\n",
    "            pbar.close()\n",
    "            save_model(model, 'xlstm_weights.pth', 'xlstm_metadata.pkl')\n",
    "\n",
    "        # Predictions and visualization\n",
    "        global comparison_df, comparison_notdf\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test_tensor)\n",
    "\n",
    "        y_pred_inverse = scaler.inverse_transform(\n",
    "            np.concatenate((y_pred.numpy(), np.zeros((y_pred.shape[0], len(cleaned_data.columns) - 1))), axis=1)\n",
    "        )[:, 0]\n",
    "        y_test_inverse = scaler.inverse_transform(\n",
    "            np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], len(cleaned_data.columns) - 1))), axis=1)\n",
    "        )[:, 0]\n",
    "\n",
    "        comparison_notdf = pd.DataFrame({\n",
    "            'True Battery Level (%)': y_test_inverse,\n",
    "            'Predicted Battery Level (%)': y_pred_inverse\n",
    "        })\n",
    "\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Timestamp': ts_test,\n",
    "            'True Battery Level (%)': y_test_inverse,\n",
    "            'Predicted Battery Level (%)': y_pred_inverse\n",
    "        })\n",
    "\n",
    "        # Plot results\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(comparison_df['Timestamp'], comparison_df['True Battery Level (%)'],\n",
    "                label='True Battery Level', color='blue', linewidth=1, marker='o', markersize=2)\n",
    "        plt.plot(comparison_df['Timestamp'], comparison_df['Predicted Battery Level (%)'],\n",
    "                label='Predicted Battery Level', color='orange', linewidth=1, marker='o', markersize=2)\n",
    "        plt.title('True vs Predicted Battery Levels with Attention-based xLSTM')\n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Battery Level (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.gca().xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nComparison Results:\")\n",
    "        display(comparison_notdf)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/mh983mrs1yj0cqv4dy1r4hxm0000gn/T/ipykernel_99990/1903801170.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('xlstm_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier enteries: \n",
      "Generated dataset with 5000 entries!\n",
      "No existing scaler found. Creating a new one.\n",
      "Scaler saved to scaler.pkl\n",
      "No existing metadata found at xlstm_metadata.pkl.\n",
      "No metadata found. Using default architecture.\n",
      "No existing model weights found. Training from scratch.\n",
      "\n",
      "Training xLSTM model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300/300 | Loss: 0.0068: 100%|███████████████████████████████| 300/300 [00:05<00:00, 56.69it/s]\n",
      "/var/folders/9z/mh983mrs1yj0cqv4dy1r4hxm0000gn/T/ipykernel_99990/1903801170.py:112: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to xlstm_weights.pth\n",
      "Model metadata saved to xlstm_metadata.pkl\n",
      "\n",
      "Comparison Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Battery Level (%)</th>\n",
       "      <th>Predicted Battery Level (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.472631</td>\n",
       "      <td>26.212905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.608695</td>\n",
       "      <td>29.787796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.255631</td>\n",
       "      <td>34.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.527181</td>\n",
       "      <td>32.206947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.282245</td>\n",
       "      <td>33.027307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.721134</td>\n",
       "      <td>33.434140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.217345</td>\n",
       "      <td>39.625406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.503790</td>\n",
       "      <td>49.462736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.629914</td>\n",
       "      <td>44.760877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.268395</td>\n",
       "      <td>48.710134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.849143</td>\n",
       "      <td>44.870135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48.965028</td>\n",
       "      <td>39.145671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57.584014</td>\n",
       "      <td>54.027960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52.519275</td>\n",
       "      <td>53.604065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63.569191</td>\n",
       "      <td>55.391819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81.052064</td>\n",
       "      <td>72.180173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73.643275</td>\n",
       "      <td>76.669333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84.478485</td>\n",
       "      <td>82.665733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>83.774475</td>\n",
       "      <td>85.798431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>88.415829</td>\n",
       "      <td>83.265704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81.428216</td>\n",
       "      <td>75.244400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True Battery Level (%)  Predicted Battery Level (%)\n",
       "0                21.472631                    26.212905\n",
       "1                30.608695                    29.787796\n",
       "2                35.255631                    34.932000\n",
       "3                35.527181                    32.206947\n",
       "4                37.282245                    33.027307\n",
       "5                34.721134                    33.434140\n",
       "6                50.217345                    39.625406\n",
       "7                50.503790                    49.462736\n",
       "8                41.629914                    44.760877\n",
       "9                58.268395                    48.710134\n",
       "10               39.849143                    44.870135\n",
       "11               48.965028                    39.145671\n",
       "12               57.584014                    54.027960\n",
       "13               52.519275                    53.604065\n",
       "14               63.569191                    55.391819\n",
       "15               81.052064                    72.180173\n",
       "16               73.643275                    76.669333\n",
       "17               84.478485                    82.665733\n",
       "18               83.774475                    85.798431\n",
       "19               88.415829                    83.265704\n",
       "20               81.428216                    75.244400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_path = \"./device_data.csv\"\n",
    "    process_data(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
